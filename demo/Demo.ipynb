{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150240fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import proxUtil #this file contains the python wrappers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e3a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run this notebook, you will need a .tsv file from the UCR repository.\n",
    "# This was previously run using the GunPoint dataset. If a different dataset\n",
    "# is desired (or required), change the following names (including file path).\n",
    "\n",
    "traindata = \"GunPoint_TRAIN.tsv\"\n",
    "testdata = \"GunPoint_TEST.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed6a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file [GunPoint_TRAIN.tsv]:finished in 0:0:0.015\n",
      "reading file [GunPoint_TEST.tsv]:finished in 0:0:0.018\n",
      "Running on configurations...\n",
      "Dataset: GunPoint_TRAIN.tsv, Training Data : 50x150 , Testing Data: 150x150, Train #Classes: 2, Test #Classes: 2\n",
      "Repeats: 1 , Trees: 12 , Candidates per Split(r): 6\n",
      "Output Dir: output, Export: 1, Verbosity: 1\n",
      "Select DM per node: true , Shuffle Data: false, JVM WarmUp: false\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "-----------------Repetition No: 1 (GunPoint_TRAIN.tsv)   -----------------\n",
      "Using: 3 MB, Free: 17 MB, Allocated Pool: 20 MB, Max Available: 1024 MB\n",
      "core.ProximityForestResult@e9e54c2\n",
      "0.1.2.3.4.5.6.7.8.9.10.11.\n",
      "Using: 14 MB, Free: 10 MB, Allocated Pool: 24 MB, Max Available: 1024 MB\n",
      "**\n",
      "Computing Forest Proximities...\n",
      "Done Computing Forest Proximities. Computation time: 7.0ms\n",
      "Training Time: 918.807369ms (0:0:0.918)\n",
      "Prediction Time: 545.646937ms (0:0:0.545)\n",
      "Correct(TP+TN): 148 vs Incorrect(FP+FN): 2\n",
      "Accuracy: 0.9866666666666667\n",
      "Error Rate: 0.013333333333333308\n",
      "REPEAT:1 ,GunPoint_TRAIN.tsv, 0.9866666666666667, 918.807369, 545.646937, 3.8333333333333335\n"
     ]
    }
   ],
   "source": [
    "# First, train the model and evaluate on the test set.\n",
    "# by default, a file with proximities (training set) is created (\"ForestProximities.txt\"), along with \n",
    "# the training labels (\"ytrain.txt\") and model predictions (on the test set) (\"Predictions.txt\").\n",
    "# The model is also saved, by default, according to the modelname parameter: \"modelname.ser\"\n",
    "proxUtil.getProx(traindata, testdata, modelname=\"TheModel\", num_trees=12, r=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726ff929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can read in the proximities and training labels as follows.\n",
    "p, y = proxUtil.getProxArrays()\n",
    "\n",
    "# Sometimes, the proximities should be symmetrized:\n",
    "p = proxUtil.SymmetrizeProx(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25863300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute within-class outlier scores.\n",
    "scores = proxUtil.getOutlierScores(p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2d9d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file [GunPoint_TEST.tsv]:finished in 0:0:0.025\n",
      "\n",
      "**\n"
     ]
    }
   ],
   "source": [
    "# We can load a saved model by passing the correct model name and applying the model\n",
    "# to a test set. The model predictions are stored in \"Predictions_saved.txt\"\n",
    "proxUtil.evalPF(testdata, modelname=\"TheModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4001e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can read in the predictions of the saved model.\n",
    "f0 = open(\"Predictions_saved.txt\")\n",
    "f1 = f0.read()\n",
    "preds = eval(\"np.array(\" + f1 + \")\")\n",
    "f0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a209c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also read in the predictions of the original model.\n",
    "f0 = open(\"Predictions.txt\")\n",
    "f1 = f0.read()\n",
    "OriginalPreds = eval(\"np.array(\" + f1 + \")\")\n",
    "f0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9bed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The saved model should be the same as the original model,\n",
    "# so the predictions should be the same. We can check this:\n",
    "np.unique([preds[i] - OriginalPreds[i] for i in range(preds.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed679efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
